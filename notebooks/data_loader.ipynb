{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590e5e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ce2141",
   "metadata": {},
   "source": [
    "# Data loading\n",
    "\n",
    "* Creating files containing all the runs for each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22308146",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting low DIV for train and high DIV for test\n",
    "models = ['MIROC6', 'CESM2', 'CanESM5', 'MIROC-ES2L', 'MPI-ESM1-2-LR']\n",
    "ref_period = ('1850-01-01', '2000-01-01')\n",
    "coarsen_factor = 12\n",
    "time_scale = 'month' # Only yearly or montly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0056ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import h5py\n",
    "\n",
    "def load_data(models, var='pr', time_scale='month', ref_period=None, path='../../AnchorMultivariateAnalysis/data/ForceSMIP/Training/Amon/tas/ForceSMIP/', coarsen_factor=None, cp_anomalies=True):\n",
    "    \"\"\"\n",
    "    Load data from NetCDF files for multiple models.\n",
    "    \n",
    "    Args:\n",
    "        models (list): List of model names.\n",
    "        var (str, optional): Variable name. Default is 'pr'.\n",
    "        time_scale (str, optional): Time scale for anomaly calculation ('month' or 'year'). Default is 'month'.\n",
    "        ref_period (tuple, optional): Reference period for anomaly calculation (start year, end year). Default is None.\n",
    "        path (str, optional): Path to the directory containing model data. Default is '../../AnchorMultivariateAnalysis/data/ForceSMIP/Training/Amon/tas/ForceSMIP/'.\n",
    "        coarsen_factor (int, optional): Coarsening factor for spatial aggregation. Default is None.\n",
    "        cp_anomalies (bool, optional): If True, compute anomalies using climatology. Default is True.\n",
    "        \n",
    "    Returns:\n",
    "        dict: Dictionary containing the loaded ensemble data.\n",
    "    \"\"\"\n",
    "    ensemble = {}\n",
    "    flag = True\n",
    "    \n",
    "    for model in models:\n",
    "        print('## Model {}'.format(model))\n",
    "        directory = path + model\n",
    "        listdir = os.listdir(directory)\n",
    "        data = None\n",
    "        ensemble[model] = {}\n",
    "        \n",
    "        for i, file in enumerate(listdir, start=1):\n",
    "            if i > 3:\n",
    "                break\n",
    "            print('File {}/{}'.format(i, len(listdir)), end='\\r')\n",
    "            file_path = os.path.join(directory, file)\n",
    "            ds = xr.open_dataset(file_path)\n",
    "            \n",
    "            # Compute anomalies\n",
    "            if time_scale == 'month':\n",
    "                if cp_anomalies:\n",
    "                    climatology = ds.groupby('time.month').mean(dim='time')\n",
    "                    anomalies = ds.groupby('time.month') - climatology\n",
    "                else:\n",
    "                    anomalies = ds\n",
    "            elif time_scale == 'year':\n",
    "                ds_yearly = ds.resample(time='1Y').mean()\n",
    "                mean_ref_period = ds_yearly.sel(time=slice(ref_period[0], ref_period[1])).mean(dim='time')\n",
    "                anomalies = ds_yearly - mean_ref_period\n",
    "            \n",
    "            # Apply coarsening if specified\n",
    "            if coarsen_factor is not None:\n",
    "                anomalies = anomalies.coarsen(lat=coarsen_factor, lon=coarsen_factor, boundary='trim').mean()\n",
    "            \n",
    "            # Store coordinate values if first iteration\n",
    "            if flag:\n",
    "                if time_scale == 'year':\n",
    "                    ensemble['time'] = np.unique(anomalies['time'])\n",
    "                elif time_scale == 'month':\n",
    "                    ensemble['time'] = anomalies['time']\n",
    "                ensemble['lat'] = anomalies['lat'].values\n",
    "                ensemble['lon'] = anomalies['lon'].values  \n",
    "                flag = False\n",
    "            \n",
    "            # Append data\n",
    "            if data is None:\n",
    "                data = [anomalies[var].values]\n",
    "            else:\n",
    "                data.append(anomalies[var].values)\n",
    "            \n",
    "            ds.close()\n",
    "        \n",
    "        ensemble[model][var] = np.array(data)\n",
    "        print()\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "def save_data(data, model='CanESM5', var='tas', data_path='../data/', name_adder='', pkl=False):\n",
    "    \"\"\"\n",
    "    Save ensemble data to NetCDF or HDF5 file.\n",
    "    \n",
    "    Args:\n",
    "        data (dict): Dictionary containing ensemble data.\n",
    "        model (str): Model name. Default is 'CanESM5'.\n",
    "        var (str): Variable name. Default is 'tas'.\n",
    "        data_path (str): Path to save the file. Default is '../data/'.\n",
    "        name_adder (str): Additional name for the file. Default is ''.\n",
    "        pkl (bool): If True, save as HDF5; otherwise, save as NetCDF. Default is False.\n",
    "    \"\"\"\n",
    "    n_members = data[model][var].shape[0]\n",
    "    \n",
    "    if not pkl:\n",
    "        with nc.Dataset(data_path + '{}_{}'.format(model, var) + name_adder + '.nc', 'w') as f:\n",
    "            f.createDimension('n_members', n_members)\n",
    "            f.createDimension('time', len(data['time']))\n",
    "            f.createDimension('lat', len(data['lat']))\n",
    "            f.createDimension('lon', len(data['lon']))\n",
    "\n",
    "            members_var = f.createVariable('n_members', 'i4', ('n_members',))\n",
    "            time_var = f.createVariable('time', 'f8', ('time',))\n",
    "            lat_var = f.createVariable('lat', 'f4', ('lat',))\n",
    "            lon_var = f.createVariable('lon', 'f4', ('lon',))\n",
    "            tas_var = f.createVariable(var, 'f4', ('n_members', 'time', 'lat', 'lon'))\n",
    "\n",
    "            members_var[:] = np.arange(n_members)\n",
    "            time_var[:] = range(1716)  # Example range\n",
    "            lat_var[:] = data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d11c56d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in ['CanESM5'] :\n",
    "    data = load_data([model], var='tas')\n",
    "    save_data(data, model=model, var='psl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c45a24e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forcesmip",
   "language": "python",
   "name": "forcesmip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
