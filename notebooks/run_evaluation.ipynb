{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import pydmd\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "\n",
    "import pydmd\n",
    "\n",
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters and load forcings\n",
    "\n",
    "# Load Forcings\n",
    "forcings_df = pd.read_csv('./data/interpolatedForcing.csv')\n",
    "forcings  = np.array(forcings_df.iloc[840:]['totalforcing'])\n",
    "\n",
    "\n",
    "data_path = './data/Evaluation-Tier1' #path to evaluation tier\n",
    "\n",
    "out_path = './predictions' #directory to save results\n",
    "\n",
    "method = 'DMDc' #your method name here\n",
    "\n",
    "\n",
    "#evaluaton variables\n",
    "dir_names = {'Aday': ['monmaxpr', 'monmaxtasmax', 'monmintasmin'],\n",
    "             'Amon': ['pr', 'psl', 'tas'],\n",
    "             'Omon': ['tos']\n",
    "            }\n",
    "\n",
    "tier = data_path[-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File 1/10\r"
     ]
    }
   ],
   "source": [
    "#load data\n",
    "\n",
    "datasets = {}\n",
    "for dir_name in dir_names.keys():\n",
    "    vars = dir_names[dir_name]\n",
    "    for var in vars:\n",
    "        # Loop through each file\n",
    "        directory = os.path.join(data_path, dir_name, var)\n",
    "        # Define the file path\n",
    "        listdir = os.listdir(directory)\n",
    "\n",
    "        data = None\n",
    "        for i, file in enumerate(listdir, start=1):\n",
    "\n",
    "            print('File {}/{}'.format(i,len(listdir)), end='\\r')\n",
    "            # Reading temperature file\n",
    "            ## Open the NetCDF file using xarray\n",
    "            file_path = os.path.join(directory, file)\n",
    "            ds = xr.open_dataset(file_path)\n",
    "\n",
    "            var_short = ds.to_dataframe().columns[0]\n",
    "\n",
    "            # Specify the coarsening factor\n",
    "            # Compute monthly anomalies\n",
    "            raw_data = np.array(ds[var_short])\n",
    "            climatology = ds[var_short].groupby('time.month').mean(dim='time')\n",
    "            anomalies = ds[var_short].groupby('time.month') - climatology\n",
    "            ds.close()\n",
    "\n",
    "            #convert to numpy array\n",
    "            tas_cube = np.array(anomalies)\n",
    "            [t, nlat, nlon] = tas_cube.shape\n",
    "            tas_all = np.reshape(tas_cube, (t, nlat*nlon))\n",
    "\n",
    "            #match the submission style\n",
    "            #$VARIABLE_$MEMBERID_$TIER_$METHOD_$GROUPNAME.nc\n",
    "            split_fpath = file_path.split('/')\n",
    "            name_memID = split_fpath[-1].split('.')[0]\n",
    "            group_name = split_fpath[-3]\n",
    "            data_name = f'{name_memID}_{tier}_{method}_{group_name}'\n",
    "\n",
    "            datasets[data_name] = tas_all\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predict forced response on the data\n",
    "\n",
    "for data_name in datasets.keys():\n",
    "    data_all  = datasets[data_name]\n",
    "\n",
    "    #remove nans\n",
    "    nan_mask = np.all(np.isfinite(data_all), axis=0)\n",
    "    data = data_all[:,nan_mask]\n",
    "\n",
    "    ################################\n",
    "    ################################\n",
    "    #YOUR METHOD HERE!\n",
    "\n",
    "    #PCA\n",
    "    pca = PCA(n_components = 3)\n",
    "    pca.fit(data)\n",
    "    data_pca = pca.transform(data)\n",
    "\n",
    "    #DMDc      \n",
    "    my_dmdc = pydmd.DMDc(svd_rank=-1)\n",
    "    my_dmdc.fit(data_pca.T, np.expand_dims(forcings[:-1],0))\n",
    "    dmdc_eigs = my_dmdc.eigs\n",
    "\n",
    "    #select mode with biggest real part\n",
    "    idx = np.argsort(np.real(dmdc_eigs))[::-1][:1]\n",
    "    sel_modes = my_dmdc.modes[:,idx]\n",
    "    sel_dynamics = my_dmdc.dynamics[idx,:]\n",
    "    sel_eigs = dmdc_eigs[idx]\n",
    "\n",
    "    #predict forced response\n",
    "    dmdc_pred_forced_resp_pca = np.linalg.multi_dot(\n",
    "                            [sel_modes, np.diag(sel_eigs), np.linalg.pinv(sel_modes), data_pca[:-1,:].T]) + my_dmdc.B @ np.expand_dims(forcings[:-1],0)\n",
    "\n",
    "    #add the mask back in\n",
    "    dmdc_pred_forced_resp = np.empty((t-1,nlat*nlon))\n",
    "    dmdc_pred_forced_resp[:, nan_mask] = pca.inverse_transform(dmdc_pred_forced_resp_pca.T.real)\n",
    "    dmdc_pred_forced_resp[:,~nan_mask] = np.nan\n",
    "\n",
    "    #reshape and predict forced response at first time as the signal at time 1\n",
    "    dmdc_pred_forced_resp = np.vstack( [tas_all[0], dmdc_pred_forced_resp] )\n",
    "    dmdc_pred_forced_resp = dmdc_pred_forced_resp.reshape((t, nlat, nlon))\n",
    "\n",
    "    ################################\n",
    "    ################################\n",
    "\n",
    "    #make a xarray object\n",
    "    forced_resp_xr = ds.copy()\n",
    "    forced_resp_xr[var_short] = ({'time':ds['time'].values,'lat': ds['lat'].values, 'lon': ds['lon'].values},dmdc_pred_forced_resp)\n",
    "    forced_resp_xr.attrs = {'creation_date': str(datetime.datetime.now()), 'evaluation_id': '1B', 'method': 'DMDc'}\n",
    "\n",
    "    #save the result\n",
    "    f_name = os.path.join(out_path, f'{data_name}.nc')\n",
    "    forced_resp_xr.to_netcdf(f_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gp_control_dmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
