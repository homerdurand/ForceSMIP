{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6271f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import xarray as xr\n",
    "import netCDF4 as nc\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "\n",
    "import datetime as dt\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeCV, Ridge, LinearRegression, Lasso, ElasticNet\n",
    "from sklearn.metrics import r2_score\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb4e78a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['CanESM5', 'MIROC-ES2L', 'MPI-ESM1-2-LR', 'MIROC6', 'CESM2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "000cc424",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model_data(model, var, path='../data/'):\n",
    "    # Loading data file\n",
    "    file_path = os.path.join(path, '{}_{}.nc'.format(model, var))\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    # Getting TAS\n",
    "    tas_array = ds[var].values\n",
    "    # Close the dataset\n",
    "    ds.close()\n",
    "    return tas_array\n",
    "\n",
    "def get_data_shape_lat_lon(model='CanESM5', var='tas', path='../data/'):\n",
    "    file_path = os.path.join(path, '{}_{}.nc'.format(model, var))\n",
    "    ds = xr.open_dataset(file_path)\n",
    "    # Getting TAS\n",
    "    shape = ds[var].values.shape\n",
    "    # Close the dataset\n",
    "    ds.close()\n",
    "    return shape, ds['lat'], ds['lon']\n",
    "\n",
    "def load_data_models(models, var='tas', n_sample=10, path='../data/'):\n",
    "    X, y = None, None\n",
    "    for model in models:\n",
    "        tas_array = load_model_data(model, var=var, path=path)\n",
    "        shape = tas_array.shape\n",
    "        \n",
    "        idxs = random.sample(range(shape[0]*shape[1]), n_sample)\n",
    "        X_temp = tas_array.reshape(shape[0]*shape[1], shape[2]*shape[3])\n",
    "        y_temp = np.tile(tas_array.mean(axis=0), (shape[0], 1, 1)) .reshape(shape[0]*shape[1], shape[2]*shape[3])\n",
    "\n",
    "        if X is None:\n",
    "            X = X_temp[idxs,:]\n",
    "            y = y_temp[idxs,:]\n",
    "        else :\n",
    "            X = np.vstack((X, X_temp[idxs,:]))\n",
    "            y = np.vstack((y, y_temp[idxs,:]))\n",
    "        del tas_array\n",
    "        del X_temp\n",
    "        del y_temp\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a10bb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape, lat, lon = get_data_shape_lat_lon()\n",
    "d = shape[2]*shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c4d9586",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 50\n",
    "models_test = random.choices(models, k=B)\n",
    "models_train = [[model for model in models if model != model_test ] for model_test in models_test ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fabf3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "occurence_models_test = Counter(models_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b5d3663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'MIROC6': 11,\n",
       "         'MPI-ESM1-2-LR': 9,\n",
       "         'MIROC-ES2L': 10,\n",
       "         'CESM2': 12,\n",
       "         'CanESM5': 8})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "occurence_models_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21608ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2000\n",
    "n_alpha = 20\n",
    "alphas = np.logspace(3, 6, n_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661ae2a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                 | 0/20 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIROC6\n",
      "MPI-ESM1-2-LR\n",
      "MIROC6\n",
      "MIROC-ES2L\n",
      "CESM2\n",
      "MIROC6\n",
      "MPI-ESM1-2-LR\n",
      "MIROC-ES2L\n",
      "CESM2\n",
      "CanESM5\n",
      "MIROC-ES2L\n",
      "MIROC-ES2L\n",
      "CanESM5\n",
      "CanESM5\n",
      "MIROC-ES2L\n",
      "CESM2\n",
      "CESM2\n",
      "CESM2\n",
      "MIROC-ES2L\n",
      "CESM2\n",
      "MPI-ESM1-2-LR\n",
      "CanESM5\n",
      "MPI-ESM1-2-LR\n",
      "MIROC6\n",
      "CESM2\n",
      "CanESM5\n",
      "CESM2\n"
     ]
    }
   ],
   "source": [
    "for alpha in tqdm(alphas):\n",
    "    weights = {model: None for model in models}\n",
    "    for m_train, m_test in zip(models_train, models_test):\n",
    "        print(m_test)\n",
    "        X_train, Y_train = load_data_models(m_train, n_sample=N)\n",
    "        X_test, Y_test = load_data_models([m_test], n_sample=N)\n",
    "        ridge = Ridge(alpha)\n",
    "        ridge.fit(X_train, Y_train)\n",
    "        if weights[m_test] is None:\n",
    "            weights[m_test] = np.hstack((ridge.coef_/occurence_models_test[m_test], (ridge.intercept_/occurence_models_test[m_test])[:,None]))\n",
    "        else:\n",
    "            weights[m_test] += np.hstack((ridge.coef_/occurence_models_test[m_test], (ridge.intercept_/occurence_models_test[m_test])[:,None]))\n",
    "    \n",
    "    # Save the weights for this alpha to a file\n",
    "    file_path = f'../weights/Ridge_weights_alpha_{alpha}_n{N}.pkl'\n",
    "    with open(file_path, 'wb') as f:\n",
    "        pickle.dump(weights, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4548630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = {}\n",
    "scores_pattern = {}\n",
    "for alpha in tqdm(alphas[3:]):\n",
    "    scores[alpha] = []\n",
    "    scores_pattern[alpha] = np.zeros(d)\n",
    "    for model in models:\n",
    "        file_path = f'../weights/Ridge_weights_alpha_{alpha}_n{N}.pkl'\n",
    "        try:\n",
    "            with open(file_path, 'rb') as f:\n",
    "                weights = pickle.load(f)\n",
    "            X_test, Y_test = load_data_models([model], var='tas')\n",
    "            A, B = weights[model][:,:-1], weights[model][:,-1]\n",
    "            Y_pred = X_test @ A.T + B \n",
    "            score_pattern = r2_score(Y_test, Y_pred, multioutput='raw_values')\n",
    "            scores_pattern[alpha] += score_pattern/len(models)\n",
    "            scores[alpha].append(score_pattern.mean())\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File for alpha={alpha} and model={model} not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970c674a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Extract scores for each alpha\n",
    "data = [scores[alpha] for alpha in alphas[3:]]\n",
    "\n",
    "# Boxplot\n",
    "plt.boxplot(data)\n",
    "\n",
    "# Set xticklabels with alpha values\n",
    "plt.xticks(range(1, len(alphas[3:]) + 1), [f'{alpha:.0f}' for alpha in alphas[3:]], rotation=45)\n",
    "\n",
    "# Set xlabel with alphas\n",
    "plt.xlabel(r'$\\alpha$')\n",
    "\n",
    "# Set ylabel with r2 score\n",
    "plt.ylabel(r'$R^2$ Score')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408aad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores = {alpha: np.mean(scores[alpha]) for alpha in alphas[3:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad507af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha_opt = alphas[3:][np.argmax(list(mean_scores.values()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecfea84",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_pattern_maps = scores_pattern[alpha_opt].reshape(len(lat), len(lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fa0813",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "# Assuming you have defined lat, lon, diff_r2_map, diff_corr_map, max_val_r2, max_val_corr\n",
    "\n",
    "# Plotting\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ax = plt.axes(projection=ccrs.Robinson())\n",
    "\n",
    "# Plot for diff_r2_map\n",
    "norm_r2 = TwoSlopeNorm(vmin=-1.0, vcenter=0, vmax=1.0)\n",
    "contour_r2 = ax.pcolormesh(lon, lat, scores_pattern_maps, transform=ccrs.PlateCarree(), cmap='coolwarm', norm=norm_r2)\n",
    "ax.coastlines()\n",
    "\n",
    "gl = ax.gridlines(draw_labels=True)\n",
    "gl.top_labels = gl.right_labels = False\n",
    "gl.xformatter = LONGITUDE_FORMATTER\n",
    "gl.yformatter = LATITUDE_FORMATTER\n",
    "gl.xlabel_style = {'size': 12}  # Longitude font size\n",
    "gl.ylabel_style = {'size': 12}  # Latitude font size\n",
    "\n",
    "ax.set_title(r'Explained variance of optimal fingerprint with $\\alpha={:.0f}$'.format(alpha_opt), fontsize=15)\n",
    "\n",
    "cb = plt.colorbar(contour_r2, ax=ax, label='R2 score differences', orientation='horizontal')\n",
    "cb.ax.tick_params(labelsize=12)\n",
    "cb.set_label(r'$R^2$ ', fontsize=12) \n",
    "\n",
    "directory = '../Results'\n",
    "plt.savefig(directory + \"/maps_R2_ridge_alpha{}.pdf\".format(alpha), format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e4c8dd",
   "metadata": {},
   "source": [
    "Potential improvement:\n",
    "* Dynamical adjustment as a preprocessing to first remove **\"Internal Variability\"**.\n",
    "* Using anchor regression to make prediction less sensitive to some specific pattern of variability (e.g. North Atlantic Oscillation)\n",
    "* Using a model for each month (making the data more linear???)\n",
    "* Using a nonlinear model (Kernel Ridge, Random Forest, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcfd48cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
